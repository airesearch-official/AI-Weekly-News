# ğŸš€ AI Weekly News â€“ January 2026
**Veo 3.1 New Features, Claude Cowork, AI uses computer like a human, long-term memory â€“ HUGE AI NEWS**

ğŸ“… Published: January 14, 2026  
ğŸ¥ Watch the full video here:  
[![Watch on YouTube](https://img.youtube.com/vi/9Qu4eqEthTc/0.jpg)](https://youtu.be/9Qu4eqEthTc)

---

## ğŸ”¥ Overview
AI just dropped too many updates at once â€” and some of them genuinely change how we use these tools day-to-day. This week, we saw major new features for Veo 3.1, Claude pushing into collaborative workflows, and AI models getting long-term memory. The pace is relentless, with surprises across video, memory, collaboration, and generative tools.

Hereâ€™s a full breakdown with source links and insights ğŸ‘‡

---

## ğŸ¬ Veo 3.1 & DreamStyle
- **Veo 3.1** gets a major update, with new features for creating native vertical videos, more expressive and dynamic results from reference images, and enhanced 4K output.
- **DreamStyle** is a unified framework for video stylization that can handle text-guided, image-guided, and video-guided stylization, outperforming competitors in style consistency and video quality.
- ğŸ“– [Veo 3.1 Announcement](https://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/)
- ğŸ”— [DreamStyle Project Page](https://lemonsky1995.github.io/dreamstyle/)

---

## ğŸ¤ Cowork & UniVideo
- **Cowork** is a new research preview from Anthropic that brings the agentic capabilities of Claude Code to general knowledge work, allowing Claude to read and modify files in a designated folder.
- **UniVideo** is a versatile, unified framework for video understanding, generation, and editing, capable of handling multi-modal instructions and generating multi-modal content.
- ğŸ“– [Cowork Announcement](https://claude.com/blog/cowork-research-preview)
- ğŸ”— [UniVideo Project Page](https://congwei1230.github.io/UniVideo/)

---

## ğŸ§  Thinking with Map & AgentCPM 4B
- **Thinking with Map** is a new AI agent from Alibaba's AMAP team that can perform image geolocalization by reasoning with maps, just like a human.
- **AgentCPM-Explore** is a new 4B parameter model from OpenBMB that achieves state-of-the-art performance for on-device agents, with deep research and tool-learning capabilities.
- ğŸ”— [Thinking with Map Project Page](https://amap-ml.github.io/Thinking-with-Map/)
- ğŸ¤— [AgentCPM-Explore on Hugging Face](https://huggingface.co/openbmb/AgentCPM-Explore)

---

## ğŸ­ DreamID V & Spirit-v1.5
- **DreamID-V** is the first Diffusion Transformer-based framework for high-fidelity video face swapping, bridging the gap between image and video domains for exceptional results.
- **Spirit-v1.5** is a top-ranked embodied AI model for robotics that has now been open-sourced, challenging the idea that only clean, curated data can be used to train effective robotic agents.
- ğŸ”— [DreamID-V Project Page](https://guoxu1233.github.io/DreamID-V/)
- ğŸ”— [Spirit-v1.5 GitHub](https://github.com/Spirit-AI-Team/spirit-v1.5)

---

## ğŸ§Š InfiniDepth & DeepTutor
- **InfiniDepth** is a new depth estimation method that represents depth as a neural implicit field, allowing for arbitrary-resolution and fine-grained depth estimation.
- **DeepTutor** is an AI-powered personalized learning assistant that can transform any document into an interactive learning experience, with dual-loop reasoning and step-by-step solutions.
- ğŸ”— [InfiniDepth Project Page](https://zju3dv.github.io/InfiniDepth/)
- ğŸ”— [DeepTutor GitHub](https://github.com/HKUDS/DeepTutor)

---

## ğŸ“ SimpleMem & Yuan 3.0
- **SimpleMem** is an efficient lifelong memory system for LLM agents that treats memory as a structured, evolving representation, achieving significant improvements in accuracy and efficiency.
- **Yuan 3.0** is a new 40B parameter Mixture-of-Experts (MoE) multimodal model from YuanLab.ai, designed for enterprise applications with a focus on high performance and low computational cost.
- ğŸ”— [SimpleMem Project Page](https://aiming-lab.github.io/SimpleMem-Page/)
- ğŸ”— [Yuan 3.0 GitHub](https://github.com/Yuan-lab-LLM/Yuan3.0)

---

## ğŸ¨ VINO & ShowUI-Ï€
- **VINO** is a unified visual generator that can handle a wide range of creative tasks, from image and video generation to stylization and editing.
- **ShowUI-Ï€** is a flow-based generative model for GUI agents that unifies clicks and continuous drags, enabling more dexterous and fine-grained control over user interfaces.
- ğŸ”— [VINO Project Page](https://sotamak1r.github.io/VINO-web/)
- ğŸ”— [ShowUI-Ï€ Project Page](https://showlab.github.io/showui-pi/)

---

## ğŸ¥ ViMoGen & NeoVerse
- **ViMoGen** is a framework for generalizable motion generation, a key component for creating realistic and controllable animations.
- **NeoVerse** is a versatile 4D world model that can perform 4D reconstruction, novel-trajectory video generation, and other downstream applications, addressing the scalability limitations of previous methods.
- ğŸ”— [ViMoGen Project Page](https://linjing7.github.io/vimogen/)
- ğŸ”— [NeoVerse Project Page](https://neoverse-4d.github.io/)

---

## ğŸ¤– RelayLLM, GaMo & VideoAuto-R1
- **RelayLLM** is a framework for efficient reasoning via collaborative decoding, designed to reduce the computational cost and latency of complex reasoning tasks.
- **GaMo** (Geometry-aware Multi-view Diffusion Outpainting) is a new method for sparse-view 3D reconstruction that uses diffusion models to generate novel views.
- **VideoAuto-R1** is a video auto-reasoning framework that can understand and reason about the content of videos, a critical capability for advanced video analysis.
- ğŸ”— [RelayLLM GitHub](https://github.com/Chengsong-Huang/RelayLLM)
- ğŸ¤— [GaMo on Hugging Face Papers](https://huggingface.co/papers/2512.25073)
- ğŸ”— [VideoAuto-R1 Project Page](https://ivul-kaust.github.io/projects/videoauto-r1/)

---

## ğŸš€ Wrap Up
This week was a testament to the rapid evolution of AI, with tools becoming more collaborative, more persistent, and more deeply integrated into our workflows.
- **Collaboration is key**: Tools like Claude Cowork are showing us a future where AI is a true partner in our work, not just a tool.
- **Memory is the next frontier**: With the introduction of long-term memory, AI assistants are becoming more useful and context-aware.
- **Video is getting smarter**: From new features in Veo 3.1 to advanced face-swapping and 3D reconstruction, AI video is becoming more powerful and realistic every day.

ğŸ‘‰ What do you think is the most significant update this week? Are you more excited about collaborative AI, long-term memory, or the latest video tools?

ğŸ’¬ Drop your thoughts in the video comments:
[Watch the full video on YouTube](https://youtu.be/9Qu4eqEthTc)

---

## ğŸ”— Follow & Support
- ğŸ¦ Twitter/X: [@airesearch_ai](https://x.com/airesearch_ai)  
- â˜• Support: [Ko-fi](https://ko-fi.com/airesearchs)  
- ğŸ¥ Subscribe for more: [AI Research YouTube](https://www.youtube.com/@airesearchofficial/)

---

#AI #AINews #AIWeekly #ArtificialIntelligence #Veo3.1 #Claude #AIMemory #AIVideo #AIResearch #AITrends

ğŸ‘‰ Browse all past episodes here: [AI Weekly News Archive](../../..)
