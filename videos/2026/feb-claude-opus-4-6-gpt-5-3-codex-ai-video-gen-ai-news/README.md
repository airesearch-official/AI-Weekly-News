# ğŸš€ AI Weekly News â€“ February 2026
**Claude Opus 4.6, GPT-5.3 Codex, #1 AI Video, New Best Music & Image Gen â€“ HUGE AI NEWS**

ğŸ“… Published: February 11, 2026  
ğŸ¥ Watch the full video here:  
[![Watch on YouTube](https://img.youtube.com/vi/__6RFnQdBRQ/0.jpg)](https://youtu.be/__6RFnQdBRQ)

---

## ğŸ”¥ Overview
AI just replaced half of creative work this week. We're seeing insane updates across the board: a new #1 AI video generator, Claude beating top models, and major breakthroughs in music and image generation. This is one of the craziest weeks in AI history.

Hereâ€™s a full breakdown with source links and insights ğŸ‘‡

---

## ğŸ§  Claude Opus 4.6 & GPT-5.3 Codex
- **Claude Opus 4.6** is Anthropic's most powerful model yet, featuring significant improvements in coding, reasoning, and long-running agentic tasks. It can now run in the background for complex workflows.
- **GPT-5.3 Codex** from OpenAI is a major upgrade to their frontier coding model, designed for interactive agentic coding and complex professional knowledge tasks.
- ğŸ“– [Claude Opus 4.6 Announcement](https://www.anthropic.com/news/claude-opus-4-6)
- ğŸ“– [GPT-5.3 Codex Announcement](https://openai.com/index/introducing-gpt-5-3-codex/)

---

## ğŸ¥ SeeDance 2.0 & Hunyuan Image 3.0
- **SeeDance 2.0** by Dreamina (CapCut) is a powerful AI video generator that allows creators to design storyboards and bring characters to life with seamless AI video creation.
- **Hunyuan Image 3.0** is Tencent's latest 80B parameter text-to-image model, offering an "Instruct" version for precise control over image generation and editing.
- ğŸ”— [SeeDance 2.0 Tools](https://dreamina.capcut.com/tools/seedance-2-0)
- ğŸ”— [Hunyuan Image 3.0 GitHub](https://github.com/Tencent-Hunyuan/HunyuanImage-3.0)

---

## ğŸ–¼ï¸ Qwen Image 2.0 & Project Genie
- **Qwen Image 2.0** is an omni-architecture model that unifies high-quality image generation and professional-level editing into a single 7B parameter system.
- **Project Genie** by Google DeepMind is an experimental research prototype that allows users to create and explore infinitely diverse interactive worlds.
- ğŸ“– [Qwen Image 2.0 Blog](https://qwen.ai/blog?id=qwen-image-2.0)
- ğŸ“– [Project Genie Blog](https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/)

---

## ğŸ¤– Lingbot World & Step 3.5 Flash
- **Lingbot World** is an open-source world model built upon Wan 2.2, designed for interactive video generation and robot control.
- **Step 3.5 Flash** is a high-speed, sparse MoE model that delivers frontier reasoning and agentic capabilities, activating only 11B parameters for maximum efficiency.
- ğŸ”— [Lingbot World GitHub](https://github.com/Robbyant/lingbot-world)
- ğŸ“– [Step 3.5 Flash Blog](https://static.stepfun.com/blog/step-3.5-flash/)

---

## ğŸ’» Qwen3 Coder Next & MiniCPM-o 4.5
- **Qwen3 Coder Next** push the boundaries of small hybrid models with a focus on large-scale executable task synthesis and environment interaction.
- **MiniCPM-o 4.5** is an omni-modal model capable of full-duplex live streaming and real-time video/audio conversation at GPT-4o levels.
- ğŸ“– [Qwen3 Coder Next Blog](https://qwen.ai/blog?id=qwen3-coder-next)
- ğŸ¤— [MiniCPM-o 4.5 on Hugging Face](https://huggingface.co/openbmb/MiniCPM-o-4_5)

---

## ğŸ¬ MOVA & Context Forcing
- **MOVA** (MOSS-Video-and-Audio) is a fully open-source MoE world model for synchronized video and audio generation.
- **Context Forcing** is a novel framework for consistent autoregressive video generation that significantly reduces drifting in long-duration videos.
- ğŸ”— [MOVA GitHub](https://github.com/OpenMOSS/MOVA)
- ğŸ”— [Context Forcing Project Page](https://chenshuo20.github.io/Context_Forcing/)

---

## ğŸ‘ï¸ Gemini 3 Flash Agentic Vision & Paper Banana
- **Gemini 3 Flash Agentic Vision** enables active image investigation, allowing the model to formulate plans to zoom, inspect, and analyze visual data via code execution.
- **PaperBanana** automates academic illustration for scientists, generating methodology diagrams and statistical plots directly for publications.
- ğŸ“– [Agentic Vision Blog](https://blog.google/innovation-and-ai/technology/developers-tools/agentic-vision-gemini-3-flash/)
- ğŸ”— [PaperBanana Project Page](https://dwzhu-pku.github.io/PaperBanana/)

---

## ğŸ§ª Omnimatte Zero & Lucy 2
- **Omnimatte Zero** is a training-free, real-time method for decomposing videos into meaningful layers for object removal and recombination.
- **Lucy 2** by Decart is a real-time world model that enables high-fidelity video editing and interaction live at 30 FPS.
- ğŸ”— [Omnimatte Zero Project Page](https://dvirsamuel.github.io/omnimattezero.github.io/)
- ğŸ”— [Lucy 2 Website](https://lucy.decart.ai/)

---

## ğŸµ UniAudio 2.0 & MiniMax Music 2.5
- **UniAudio 2.0** is a unified audio foundation model for speech, sound, and music, trained on a massive 100B text and 60B audio tokens.
- **MiniMax Music 2.5** brings studio-grade pop production and narrative film scoring to AI music generation with deep melodic logic.
- ğŸ”— [UniAudio 2.0 Project Page](https://dongchaoyang.top/UniAudio2Demo/)
- ğŸ“– [MiniMax Music 2.5 News](https://www.minimax.io/news/minimax-music-25)

---

## ğŸ‘¤ Interact Avatar & NVIDIA Earth-2
- **Interact Avatar** enables text-driven human-object interaction for talking avatars, generating realistic grounded actions.
- **NVIDIA Earth-2** is an open model family for global weather forecasting and climate simulation, accessible via Earth2Studio.
- ğŸ”— [Interact Avatar Project Page](https://interactavatar.github.io/)
- ğŸ“– [NVIDIA Earth-2 Blog](https://blogs.nvidia.com/blog/nvidia-earth-2-open-models/)

---

## ğŸ¨ Edit Yourself & SkinTokens
- **Edit Yourself** is a video-to-video diffusion framework for precise lip synchronization and face editing.
- **SkinTokens** is a novel discrete representation for skinning weights, enabling high-fidelity 3D character rigging and animation.
- ğŸ”— [Edit Yourself Project Page](https://edit-yourself.github.io/)
- ğŸ”— [SkinTokens Project Page](https://zjp-shadow.github.io/works/SkinTokens/)

---

## ğŸ”¬ Intern-S1 Pro & GLM-OCR
- **Intern-S1 Pro** is a trillion-scale MoE multimodal scientific reasoning model with 1T total parameters.
- **GLM-OCR** is an accurate and fast multimodal OCR model for complex document understanding, built on a vision-language encoder-decoder.
- ğŸ”— [Intern-S1 GitHub](https://github.com/InternLM/Intern-S1)
- ğŸ”— [GLM-OCR GitHub](https://github.com/zai-org/GLM-OCR)

---

## ğŸ­ TeleStyle & FS-Video & Rolling Sink
- **TeleStyle** is a content-preserving style transfer framework for images and videos based on Qwen-Image-Edit.
- **FS-Video** is a video generation framework featuring a highly-compressed latent space and diffusion transformer architecture.
- **Rolling Sink** is a technique for efficient long-context generation in streaming video models.
- ğŸ”— [TeleStyle Project Page](https://tele-ai.github.io/TeleStyle/)
- ğŸ”— [FS-Video Project Page](https://kingofprank.github.io/fsvideo/)
- ğŸ”— [Rolling Sink GitHub](https://rolling-sink.github.io/)

---

## ğŸš€ Wrap Up
This week was a testament to how fast AI is moving from research to production. With Claude Opus 4.6 and GPT-5.3 Codex, agentic workflows are becoming the new standard. Real-time video generation and studio-grade music are now accessible to everyone.
- **Agentic coding is here**: New models are no longer just writing code; they are managing entire codebases independently.
- **Multimodal is the default**: From OCR to music and interactive worlds, AI is now truly omni-modal.
- **Efficiency meets power**: Sparse MoE architectures like Step 3.5 Flash are proving that we can have frontier intelligence with much lower compute costs.

ğŸ‘‰ Which of these breakthroughs are you most excited to try first?

ğŸ’¬ Drop your thoughts in the video comments:
[Watch the full video on YouTube](https://youtu.be/__6RFnQdBRQ)

---

## ğŸ”— Follow & Support
- ğŸ¦ Twitter/X: [@airesearch_ai](https://x.com/airesearch_ai)  
- â˜• Support: [Ko-fi](https://ko-fi.com/airesearchs)  
- ğŸ¥ Subscribe for more: [AI Research YouTube](https://www.youtube.com/@airesearchofficial/)

---

#AI #AINews #AIWeekly #ArtificialIntelligence #Claude #OpenAI #AIVideo #AIMusic #AIResearch

ğŸ‘‰ Browse all past episodes here: [AI Weekly News Archive](../../..)
