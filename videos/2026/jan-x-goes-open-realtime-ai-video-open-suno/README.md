# ğŸš€ AI Weekly News â€“ January 2026
**X Goes Open, Realtime AI Video, Open-Source SUNO, New Open NanoBanana â€“ HUGE AI NEWS**

ğŸ“… Published: January 21, 2026  
ğŸ¥ Watch the full video here:  
[![Watch on YouTube](https://img.youtube.com/vi/a2a4QkkeMZA/0.jpg)](https://youtu.be/a2a4QkkeMZA)

---

## ğŸ”¥ Overview
This week, open-source AI took a massive step forward â€” and itâ€™s not just one announcement, itâ€™s a wave. From the X (Twitter) algorithm going open source to a new open-source alternative to SUNO, the theme of the week is openness, speed, and real-world usability. We're seeing powerful new tools that are changing how we create and interact with AI.

Hereâ€™s a full breakdown with source links and insights ğŸ‘‡

---

## ğŸŒ FLUX.2 [klein] & GLM-4.7 Flash
- **FLUX.2 [klein]** is a new family of fast image models from Black Forest Labs that unifies generation and editing in a single compact architecture, delivering state-of-the-art quality in under a second.
- **GLM-4.7 Flash** is the latest high-performance model from Zhipu AI, optimized for speed and efficiency in coding, reasoning, and general-purpose applications.
- ğŸ“– [FLUX.2 [klein] Announcement](https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence)
- ğŸ¤— [GLM-4.7 Flash on Hugging Face](https://huggingface.co/zai-org/GLM-4.7-Flash)

---

## ğŸ¤– ShowUI-Aloha & TranslateGemma
- **ShowUI-Aloha** is a human-taught computer-use agent that learns workflows from demonstrations on real Windows and macOS desktops, offering an open-source alternative to tools like Claude Cowork.
- **TranslateGemma** is a new family of open translation models from Google, built on Gemma 3, that helps people communicate across 55 languages.
- ğŸ”— [ShowUI-Aloha Project Page](https://showlab.github.io/Aloha_Page/)
- ğŸ“– [TranslateGemma Announcement](https://blog.google/innovation-and-ai/technology/developers-tools/translategemma/)

---

## ğŸ§Š ShapeR & HeartMula
- **ShapeR** is a novel approach from Meta AI for generative, object-centric 3D reconstruction from casual image sequences, capable of producing metric-scale 3D shapes.
- **HeartMula** is a family of open-source Music Foundation Models that provides a full suite of tools for music understanding and generation, including an audio-text alignment model, a lyric recognizer, and a high-fidelity music codec.
- ğŸ”— [ShapeR Project Page](https://facebookresearch.github.io/ShapeR/)
- ğŸ”— [HeartMula Project Page](https://heartmula.github.io/)

---

## ğŸ¨ VIBE & ğ• algorithm
- **VIBE** (Visual Instruction Based Editor) is a new framework for editing images based on visual instructions, allowing for more intuitive and precise control over edits.
- **ğ• algorithm**: The core recommendation algorithm powering the "For You" feed on X has been open-sourced by xAI, revealing the inner workings of one of the world's largest recommendation systems.
- ğŸ”— [VIBE Project Page](https://riko0.github.io/VIBE/)
- ğŸ”— [ğ• algorithm on GitHub](https://github.com/xai-org/x-algorithm)

---

## ğŸ¥ VerseCrafter & Pocket TTS
- **VerseCrafter** is a 4D-aware video world model that can generate dynamic, realistic video worlds with precise control over camera and object motion.
- **Pocket TTS** is a lightweight, high-quality text-to-speech model from Kyutai Labs that runs efficiently on CPUs and supports voice cloning.
- ğŸ”— [VerseCrafter Project Page](https://sixiaozheng.github.io/VerseCrafter_page/)
- ğŸ”— [Pocket TTS on GitHub](https://github.com/kyutai-labs/pocket-tts)

---

## ğŸ‘¤ UniSH & RigMo
- **UniSH** is a unified, feed-forward framework for joint metric-scale 3D scene and human reconstruction from a single monocular image.
- **RigMo** is a part-aware motion generation framework that allows for fine-grained control over individual body parts, enabling the creation of complex and asynchronous movements.
- ğŸ”— [UniSH Project Page](https://murphylmf.github.io/UniSH/)
- ğŸ”— [RigMo Project Page](https://rigmo-page.github.io/)

---

## ğŸ¬ FrankenMotion & NovaSR
- **FrankenMotion** is a diffusion-based, part-aware motion generation framework that allows each body part to be guided by its own temporally-structured text prompt.
- **NovaSR** is a tiny, 50kB audio upsampling model that can upscale muffled 16kHz audio to clear 48kHz audio at speeds over 3500x realtime.
- ğŸ”— [FrankenMotion Project Page](https://coral79.github.io/frankenmotion/)
- ğŸ”— [NovaSR on GitHub](https://github.com/ysharma3501/NovaSR)

---

## ğŸš€ AnyDepth & PixVerse R1
- **AnyDepth** is a simple and efficient training framework for zero-shot monocular depth estimation that significantly reduces model parameters and computational cost while maintaining competitive accuracy.
- **PixVerse R1** is a next-generation real-time world model that enables fluid and instant video generation in response to user input, moving beyond static clips to continuous, coherent simulations.
- ğŸ”— [AnyDepth Project Page](https://aigeeksgroup.github.io/AnyDepth/)
- ğŸ“– [PixVerse R1 Announcement](https://pixverse.ai/en/blog/pixverse-r1-next-generation-real-time-world-model)

---

## ğŸš€ Wrap Up
This week was a huge win for open-source AI. The release of the X algorithm, a powerful open-source alternative to SUNO, and a new NanoBanana update are all major steps forward. The trend is clear: AI is becoming more open, more efficient, and more integrated into real-world workflows.
- **Openness is accelerating**: From social media algorithms to music generation, the open-source community is driving innovation.
- **Real-time is here**: Real-time video generation and ultra-fast audio upsampling are becoming practical and accessible.
- **Efficiency is key**: We're seeing a new wave of small, powerful models that can run on local hardware without sacrificing quality.

ğŸ‘‰ What do you think is the most exciting open-source release this week? Are you more interested in the X algorithm, the new music generation tools, or something else?

ğŸ’¬ Drop your thoughts in the video comments:
[Watch the full video on YouTube](https://youtu.be/a2a4QkkeMZA)

---

## ğŸ”— Follow & Support
- ğŸ¦ Twitter/X: [@airesearch_ai](https://x.com/airesearch_ai)  
- â˜• Support: [Ko-fi](https://ko-fi.com/airesearchs)  
- ğŸ¥ Subscribe for more: [AI Research YouTube](https://www.youtube.com/@airesearchofficial/)

---

#AI #AINews #AIWeekly #ArtificialIntelligence #OpenSource #XAlgorithm #AIVideo #SUNO #NanoBanana #AIResearch

ğŸ‘‰ Browse all past episodes here: [AI Weekly News Archive](../../..)
