# ğŸš€ AI Weekly News â€“ November 2025
**Crazy Deepfakes, NEW Flux.2, GPT-5.1, AI Plays Any Game, Best Open Source TTS â€“ HUGE AI NEWS**

ğŸ“… Published: November 18, 2025  
ğŸ¥ Watch the full video here:  
[![Watch on YouTube](https://img.youtube.com/vi/6tF8zKKouMs/0.jpg)](https://youtu.be/6tF8zKKouMs)

---

## ğŸ”¥ Overview
This week was one of the wildest in AI history, with massive breakthroughs in deepfake technology, foundation models, and AI for gaming. We saw the release of GPT-5.1, the next generation of the FLUX image model, and AI agents that can learn to play any video game in real-time. The pace of innovation is accelerating to a ridiculous degree.

Hereâ€™s a full breakdown with source links and insights ğŸ‘‡

---

## ğŸ—£ï¸ Scribe v2 Realtime
- ElevenLabs has launched **Scribe v2 Realtime**, the most accurate low-latency speech-to-text model available.
- It delivers instant transcription in over 90 languages with just 150ms of latency, making it perfect for real-time agents and conversational AI.
- This is a major step forward for building natural, human-sounding AI agents that can understand and respond in real-time.
- ğŸ“– [Read the Announcement](https://elevenlabs.io/blog/introducing-scribe-v2-realtime)

---

## ğŸ§  GPT-5.1
- OpenAI has released **GPT-5.1**, a significant upgrade to its flagship model that makes ChatGPT smarter and more conversational.
- The new models, **GPT-5.1 Instant** and **GPT-5.1 Thinking**, use adaptive reasoning to decide when to spend more time on challenging questions, resulting in more thorough and accurate answers.
- This update also introduces personality presets, allowing users to customize ChatGPT's tone and style.
- ğŸ“– [Read the Announcement](https://openai.com/index/gpt-5-1/)

---

## ğŸŒ PhysWorld â€“ Robot Learning from a Physical World Model
- **PhysWorld** is a novel framework that enables robot learning from video generation through physical world modeling.
- It can synthesize photorealistic visual demonstrations from language commands and learn physics-consistent dynamics from limited real-world data.
- This is a breakthrough for training robots to interact with deformable objects and complex environments.
- ğŸ”— [PhysWorld Project Page](https://pointscoder.github.io/PhysWorld_Web/)

---

## ğŸ­ Recast â€“ AI Character Swap
- Higgsfield's **Recast** feature allows for hyper-realistic AI face and character swaps in videos.
- Users can record themselves once and then generate videos with any character, voice, and scene, with perfect lip-sync and lighting.
- This technology is set to revolutionize content creation, allowing for infinite creative possibilities.
- ğŸŒ [Try Recast](https://higgsfield.ai/app/recast)

---

## ğŸ¤” VibeThinker 1.5B
- WeiboAI has released **VibeThinker-1.5B**, a tiny 1.5B parameter model with massive reasoning capabilities.
- Using an innovative training method, it demonstrates superior performance compared to much larger models, even outperforming some closed-source giants.
- This proves that smaller, more accessible models can achieve state-of-the-art reasoning performance.
- ğŸ”— [VibeThinker GitHub](https://github.com/WeiboAI/VibeThinker)

---

## ğŸ‰ Ernie 5.0
- Baidu has unveiled **ERNIE 5.0**, its next-generation, natively omni-modal foundation model.
- It jointly models text, images, audio, and video, achieving frontier performance that is comparable to top international models like Gemini 2.5 Pro and GPT-5.
- This is a major milestone for multimodal AI, with world-leading image and video generation capabilities.
- ğŸŒ [Learn about Ernie 5.0](https://ernie.baidu.com/)

---

## ğŸƒ Time to Move
- **Time-to-Move (TTM)** is a new, training-free technique for motion-controlled video generation.
- It's a plug-and-play method that can be integrated into any image-to-video diffusion model, allowing users to specify motion and control the generated video.
- This provides a new level of creative control for generating dynamic and precise video content.
- ğŸ”— [Time to Move Project Page](https://time-to-move.github.io/)

---

## ğŸ”Š Step Audio EditX
- **Step Audio EditX** is a powerful new 3B-parameter model for zero-shot voice cloning and emotion control.
- It surpasses other models in both cloning accuracy and the ability to edit the emotional expression of the generated audio.
- This is the new state-of-the-art for open-source text-to-speech with fine-grained emotional control.
- ğŸ”— [Step Audio EditX GitHub](https://github.com/stepfun-ai/Step-Audio-EditX)

---

## ğŸ® Unreal Engine 5.7
- Epic Games has released **Unreal Engine 5.7**, bringing a host of new tools for building expansive, lifelike worlds.
- The update includes industry-standard rigging flexibility, enhanced animation tools, and significant improvements to the Nanite and Lumen systems.
- This release empowers creators to build incredibly detailed and dynamic real-time experiences.
- ğŸ“– [Read the Release Notes](https://www.unrealengine.com/en-US/news/unreal-engine-5-7-is-now-available)

---

## ğŸ¤– SIMA 2 â€“ The AI Gaming Companion
- Google DeepMind has introduced **SIMA 2**, the next generation of its generalist AI agent for 3D virtual worlds.
- By integrating the advanced capabilities of Gemini, SIMA is evolving from an instruction-follower into an interactive gaming companion that can play, reason, and learn alongside a human player.
- This is a major step towards creating AI agents that can master any video game.
- ğŸ“– [Read the Announcement](https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/)

---

## âœ¨ Lumine â€“ AI for Creativity
- **Lumine** is a new AI platform focused on providing tools for creative expression.
- While still in early stages, it aims to offer a suite of AI-powered features for artists, designers, and creators.
- This is another example of the growing ecosystem of AI tools built to augment human creativity.
- ğŸŒ [Visit Lumine AI](https://www.lumine-ai.org/)

---

## ğŸŒ Marble World Model
- World Labs has launched **Marble**, its first commercial product and a major breakthrough in generative world models.
- Marble can generate persistent, navigable, and controllable 3D worlds from a single image and text prompt.
- This technology is a huge step towards creating AI systems that can perceive, generate, and interact with 3D environments.
- ğŸ“– [Read the Announcement](https://www.worldlabs.ai/blog/marble-world-model)

---

## ğŸ‘€ Vision Model Alignment
- Google DeepMind has developed a new method for better aligning AI vision models with human knowledge.
- By teaching AI to see the world more like we do, they can improve the robustness and generalization of these systems.
- This is a critical step towards building more intuitive and trustworthy AI.
- ğŸ“– [Read the Blog Post](https://deepmind.google/blog/teaching-ai-to-see-the-world-more-like-we-do/)

---

## ğŸ‘• EVTAR â€“ Virtual Try-On
- **EVTAR** is a new end-to-end virtual try-on model that can directly fit a target garment onto a person in an image.
- It uses reference images to enhance the model's ability to preserve and accurately depict clothing details.
- This is a major advancement for e-commerce and virtual fashion.
- ğŸ”— [EVTAR GitHub](https://github.com/360CVGroup/EVTAR)

---

## ğŸ¨ Black Forest Labs Flux.2
- Black Forest Labs has released the **FLUX.2** model family, the next generation of their powerful image generation model.
- **FLUX.2 [pro]** offers state-of-the-art performance with exceptional prompt adherence and visual quality.
- The **FLUX.2 [dev]** weights have been released for free, making this powerful technology accessible to the open-source community.
- ğŸŒ [Learn about FLUX.2](https://flux2.io/flux2-model-family/)

---

## ğŸš€ Wrap Up
This week was a whirlwind of progress, with AI models becoming more capable, more accessible, and more integrated into our digital and physical worlds.
- Foundation models like GPT-5.1 and Ernie 5.0 are pushing the boundaries of intelligence.
- AI is becoming a true creative partner with tools like Flux.2, Recast, and Step Audio EditX.
- World models and gaming agents are bringing us closer to AI that can understand and interact with complex, dynamic environments.

ğŸ‘‰ What do you think? Which update will have the biggest impact â€” GPT-5.1, Flux.2, or the new gaming AI?

ğŸ’¬ Drop your thoughts in the video comments:
[Watch the full video on YouTube](https://youtu.be/6tF8zKKouMs)

---

## ğŸ”— Follow & Support
- ğŸ¦ Twitter/X: [@airesearch_ai](https://x.com/airesearch_ai)  
- â˜• Support: [Ko-fi](https://ko-fi.com/airesearchs)  
- ğŸ¥ Subscribe for more: [AI Research YouTube](https://www.youtube.com/@airesearchofficial/)

---

#AI #AINews #AIWeekly #ArtificialIntelligence #GPT5 #Flux2 #Deepfake #AIGaming #OpenSource #AIResearch #AITrends

ğŸ‘‰ Browse all past episodes here: [AI Weekly News Archive](../../..)
