# ğŸš€ AI Weekly News â€“ December 2025
**New #1 Open AI Model, Photoshop Killer AI, Realtime Video & Gemini 3 Flash â€“ HUGE AI NEWS**

ğŸ“… Published: December 24, 2025  
ğŸ¥ Watch the full video here:  
[![Watch on YouTube](https://img.youtube.com/vi/H2RMD1PhrAc/0.jpg)](https://youtu.be/H2RMD1PhrAc)

---

## ğŸ”¥ Overview
Another insane week in AI! From a new #1 open-source model to an AI that might finally kill Photoshop, the pace of innovation is getting wild. This week saw breakthroughs in realtime video, powerful new image editing tools, and major updates to foundation models that are changing the game.

Hereâ€™s a full breakdown with source links and insights ğŸ‘‡

---

## ğŸ§  GLM-4.7 & Gemini 3 Flash
- **GLM-4.7** is the latest model from Zhipu AI, with major advancements in coding, reasoning, and design capabilities. It introduces "Preserved Thinking" to maintain reasoning chains and offers more aesthetically pleasing design solutions.
- **Gemini 3 Flash** is Google's new fast and cost-effective model, now widely available across the Gemini app, Search, and developer APIs. It's built for speed and high-frequency workflows.
- ğŸ“– [GLM-4.7 Announcement](https://z.ai/blog/glm-4.7)
- ğŸ“– [Gemini 3 Flash Announcement](https://blog.google/products/gemini/gemini-3-flash/)

---

## âš¡ MiMo V2 Flash & LongVie 2
- **MiMo V2 Flash** is a new Mixture-of-Experts (MoE) model from Xiaomi with 309B total parameters (15B active), designed for efficient, high-performance reasoning.
- **LongVie 2** is an end-to-end framework for generating ultra-long videos. It uses multi-modal guidance to improve controllability and temporal coherence, marking a significant step toward unified video world modeling.
- ğŸ“– [MiMo V2 Flash Announcement](https://mimo.xiaomi.com/blog/mimo-v2-flash)
- ğŸ”— [LongVie 2 Project Page](https://vchitect.github.io/LongVie2-project/)

---

## ğŸ¨ Flux.2 Max & GPT Image 1.5
- **Flux.2 Max** is the highest quality model in the FLUX.2 family from Black Forest Labs, delivering professional-grade image generation and editing with unmatched consistency.
- **GPT Image 1.5** is OpenAI's next-generation visual synthesis model with sharper fidelity, stronger prompt alignment, and better reasoning capabilities than its predecessors.
- ğŸ”— [Flux.2 Max](https://bfl.ai/models/flux-2-max)
- ğŸ“– [GPT Image 1.5 Announcement](https://openai.com/index/new-chatgpt-images-is-here/)

---

## ğŸ–¼ï¸ Qwen Image Layered & Qwen Image Edit 2511
- **Qwen-Image-Layered** is a revolutionary model that can decompose an image into multiple editable RGBA layers, unlocking inherent editability similar to professional design software.
- **Qwen-Image-Edit-2511** is an updated version of Qwen's image editing model, now with built-in support for popular community-created LoRAs, making it more versatile than ever.
- ğŸ¤— [Qwen-Image-Layered on Hugging Face](https://huggingface.co/Qwen/Qwen-Image-Layered)
- ğŸ¤— [Qwen-Image-Edit-2511 on Hugging Face](https://huggingface.co/Qwen/Qwen-Image-Edit-2511)

---

## ğŸ§Š Trellis 2 & LongCat Video Avatar
- **Trellis 2** is Microsoft's state-of-the-art large 3D generative model for high-fidelity image-to-3D generation.
- **LongCat-Video-Avatar** is a unified model for creating super-realistic, lip-synchronized long videos of talking avatars, addressing issues like static behavior during silent segments.
- ğŸ”— [Trellis 2 Project Page](https://microsoft.github.io/TRELLIS.2/)
- ğŸ”— [LongCat-Video-Avatar Project Page](https://meigen-ai.github.io/LongCat-Video-Avatar/)

---

## ğŸŒ HY World 1.5 & MiniMax M2.1
- **HY World 1.5** is Tencent's real-time, interactive world model. It uses a streaming video diffusion model to enable long-term geometric consistency at 24 FPS.
- **MiniMax M2.1** is an enhanced model from MiniMax with improved multi-language programming, reasoning, and native mobile development capabilities.
- ğŸ”— [HY World 1.5 Project Page](https://3d-models.hunyuan.tencent.com/world/)
- ğŸ“– [MiniMax M2.1 Announcement](https://www.minimax.io/news/minimax-m21)

---

## ğŸ’ƒ Seedance 1.5 Pro & SCAIL
- **Seedance 1.5 Pro** is a joint audio-video model from ByteDance that accurately follows complex instructions to generate high-fidelity visuals and synchronized audio simultaneously.
- **SCAIL** is a framework for studio-grade character animation via in-context learning, enabling high-fidelity animation under diverse conditions.
- ğŸ”— [Seedance 1.5 Pro](https://seed.bytedance.com/en/seedance1_5_pro)
- ğŸ”— [SCAIL Project Page](https://teal024.github.io/SCAIL/)

---

## âœ¨ Luma Ray 3 Modify & RealVideo
- **Luma Ray 3 Modify** is a new model from Luma AI for hybrid-AI workflows, allowing for precise keyframe and character reference controls to edit and reimagine videos.
- **RealVideo** is a real-time streaming conversational video system from Zhipu AI that transforms text interactions into continuous, high-fidelity video responses.
- ğŸ“– [Luma Ray 3 Modify Announcement](https://lumalabs.ai/blog/news/ray3-modify)
- ğŸ“– [RealVideo Announcement](https://z.ai/blog/realvideo)

---

## ğŸ¥ EgoX, SVG-T2I & V-RGBX
- **EgoX** is a framework for translating third-person videos into first-person videos, preserving content while synthesizing new views.
- **SVG-T2I** is a text-to-image diffusion framework that generates images directly in the Visual Foundation Model (VFM) representation space.
- **V-RGBX** is a video editing framework with accurate controls over intrinsic properties like reflectance, illumination, and geometry.
- ğŸ”— [EgoX Project Page](https://keh0t0.github.io/EgoX/)
- ğŸ”— [SVG-T2I GitHub](https://github.com/KlingTeam/SVG-T2I)
- ğŸ”— [V-RGBX GitHub](https://github.com/Aleafy/V-RGBX)

---

## ğŸš€ Wrap Up
This week was a massive leap forward, with AI tools becoming powerful enough to replace entire creative workflows. The line between professional and AI-generated content is blurring faster than ever.
- Open-source models are not just catching up; they're starting to lead in key benchmarks.
- Image and video editing are becoming more intuitive and powerful, with layer-based editing and real-time generation becoming a reality.
- The speed and efficiency of models like Gemini 3 Flash are making advanced AI accessible to everyone.

ğŸ‘‰ What do you think? Is this the end of Photoshop as we know it? Which tool are you most excited to try?

ğŸ’¬ Drop your thoughts in the video comments:
[Watch the full video on YouTube](https://youtu.be/H2RMD1PhrAc)

---

## ğŸ”— Follow & Support
- ğŸ¦ Twitter/X: [@airesearch_ai](https://x.com/airesearch_ai)  
- â˜• Support: [Ko-fi](https://ko-fi.com/airesearchs)  
- ğŸ¥ Subscribe for more: [AI Research YouTube](https://www.youtube.com/@airesearchofficial/)

---

#AI #AINews #AIWeekly #ArtificialIntelligence #OpenSource #Photoshop #AIVideo #Gemini3 #AIResearch #AITrends

ğŸ‘‰ Browse all past episodes here: [AI Weekly News Archive](../../..)
