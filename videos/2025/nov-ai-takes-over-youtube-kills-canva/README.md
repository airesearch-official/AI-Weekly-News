# ğŸš€ AI Weekly News â€“ November 2025
**AI Just Took Over YouTube, New AI Kills Canva, ai images, game agents, character swap - Huge AI NEWS**

ğŸ“… Published: November 4, 2025  
ğŸ¥ Watch the full video here:  
[![Watch on YouTube](https://img.youtube.com/vi/9I8m1pqXIRU/0.jpg)](https://youtu.be/9I8m1pqXIRU)

---

## ğŸ”¥ Overview
This week, the AI world exploded with game-changing updates across every major vertical. We saw the first true AI operating system for workflows, a new Canva-killer from Google, and AI models that can generate infinite-length videos and even manage YouTube channels from scratch. The pace is relentless, and the results are mind-blowing.

Hereâ€™s a full breakdown with source links and insights ğŸ‘‡

---

## âš™ï¸ FlowWithOS â€“ The AI Operating System
- **FlowWithOS** has launched as the world's first operating system built for AI-powered workflows.
- It's a visual, agent-powered OS designed to move beyond simple chatbots and help users complete real work.
- This represents a major step towards a future where AI is not just a tool, but a collaborative partner in our daily tasks.
- ğŸŒ [Try FlowWithOS](https://try.flowith.io/flowithos)

---

## ğŸ¬ LongCatVideo & LongCat-Flash-Omni
- The **LongCat** team has released two groundbreaking models: **LongCatVideo** and **LongCat-Flash-Omni**.
- **LongCatVideo** is the first open-source model that can generate minutes-long, coherent videos without color drift or hallucinations.
- **LongCat-Flash-Omni** is a state-of-the-art, 560B parameter omni-modal model that excels at real-time audio-visual interaction, rivaling top proprietary models.
- ğŸ”— [LongCat-Flash-Omni GitHub](https://github.com/meituan-longcat/LongCat-Flash-Omni)

---

## â³ ChronoEdit â€“ Temporal Reasoning for Image Editing
- NVIDIA's **ChronoEdit** reframes image editing as a video generation task to ensure physical and temporal consistency.
- It imagines a short trajectory of how an edit should unfold, guiding the process to produce more realistic and coherent results.
- This is a major step forward for creating believable edits, especially for world simulation tasks.
- ğŸ”— [ChronoEdit Project Page](https://research.nvidia.com/labs/toronto-ai/chronoedit/)

---

## ğŸ¨ Emu 3.5 â€“ Meta's New Multimodal AI
- **Emu 3.5** is Meta's latest and most powerful multimodal model, designed for both generation and editing.
- Pre-trained on over 10 trillion tokens of interleaved vision-language data, it exhibits remarkable world-modeling abilities.
- It can handle interleaved image-text generation and high-quality single-image editing, making it a versatile creative partner.
- ğŸ”— [Emu 3.5 GitHub](https://github.com/baaivision/Emu3.5)

---

## âœ¨ Google Pomelli â€“ The AI Canva Killer
- Google has launched **Pomelli**, a new AI marketing tool that helps small businesses create on-brand social media campaigns.
- By simply analyzing a website, Pomelli generates tailored campaign ideas and marketing assets, effectively acting as a one-click design agency.
- This tool is a direct challenger to platforms like Canva, offering powerful, brand-aware design capabilities.
- ğŸŒ [About Pomelli](https://labs.google.com/pomelli/about/)

---

## â˜• Mocha â€“ 3D Character Generation
- **Mocha** is a new framework for generating high-quality, animatable 3D human characters from text or image prompts.
- It focuses on creating characters with realistic clothing and hair, which have traditionally been challenging for AI models.
- This technology is a significant advancement for creating lifelike characters for gaming, VR, and animation.
- ğŸ”— [Mocha Project Page](https://orange-3dv-team.github.io/MoCha/)

---

## ğŸ¤– THOR â€“ Human-Level Robot Reactions
- **THOR** is a new framework for enabling humanoids to generate human-like, whole-body reactions to intense, contact-rich interactions.
- It uses a combination of simulation and real-world data to train robots to maintain stability and perform tasks in dynamic environments.
- This is a critical step towards creating robots that can operate safely and effectively alongside humans.
- ğŸ“„ [Read the Paper](https://arxiv.org/pdf/2510.26280)

---

## ğŸ—ï¸ IGGT â€“ Semantic 3D Reconstruction
- **IGGT (Instance-Grounded Geometry Transformer)** is a novel transformer-based architecture for semantic 3D reconstruction.
- It can simultaneously predict geometric structures and corresponding instance features from multiple images.
- This allows for a more holistic and accurate understanding of 3D scenes.
- ğŸ”— [IGGT GitHub](https://github.com/lifuguan/IGGT_official)

---

## âœï¸ GRAG â€“ Drag-Based Image Editing
- **GRAG (Generative-Replace-And-Ground)** is a new approach to drag-based image editing that offers more precise control.
- It allows users to manipulate images by simply dragging points, with the AI intelligently editing the image to match.
- This provides a more intuitive and interactive way to edit images compared to text-based prompts.
- ğŸ”— [GRAG Project Page](https://little-misfit.github.io/GRAG-Image-Editing/)

---

## ğŸµ Minimax Music 2.0
- **Minimax Music 2.0** is a new AI music generation model that produces incredibly realistic vocals and high-quality audio.
- It can master a wide range of singing styles and generate music that is nearly indistinguishable from human-produced tracks.
- This release is a major step forward for AI-powered music creation.
- ğŸŒ [Read about Minimax Music 2.0](https://www.minimaxi.com/news/minimax-music-20)

---

## ğŸ“ Kimi Linear
- MoonshotAI has released **Kimi Linear**, a hybrid linear attention architecture that can handle sequences of up to 1 million tokens.
- It outperforms traditional full attention methods in many contexts while being significantly more efficient.
- This is a major breakthrough for processing extremely long documents, codebases, or conversations.
- ğŸ”— [Kimi Linear GitHub](https://github.com/MoonshotAI/Kimi-Linear)

---

## ğŸ’¨ AMD Nitro-E
- AMD has released **Nitro-E**, a family of highly efficient text-to-image diffusion models.
- With only 304M parameters, Nitro-E is designed to be resource-friendly for both training and inference, making high-quality image generation more accessible.
- It can be trained from scratch in just 1.5 days on a single node of 8 AMD Instinctâ„¢ MI300X GPUs.
- ğŸ”— [Nitro-E GitHub](https://github.com/AMD-AGI/Nitro-E)

---

## ğŸ® Game-TARS â€“ AI Game Agents
- **Game-TARS** is a new framework for creating generalist AI agents for gaming.
- These agents can learn, adapt, and play a wide variety of games in real-time, demonstrating a new level of general game-playing intelligence.
- This research is a step towards creating AI agents that can master complex, dynamic environments.
- ğŸ”— [Game-TARS Project Page](https://seed-tars.com/game-tars/)

---

## ğŸ¨ Diffusion Model without VAE
- Researchers have developed a new **Latent Diffusion Model that operates without a Variational Autoencoder (VAE)**.
- This new approach simplifies the architecture and can lead to more efficient training and inference.
- It's a significant technical innovation in the world of diffusion models.
- ğŸ”— [Project Page](https://howlin-wang.github.io/svg/)

---

## ğŸŒ WorldGrow â€“ Infinite 3D World Generation
- **WorldGrow** is a generative method for creating infinite, explicit 3D worlds.
- It uses a hierarchical framework to generate endless, explorable environments, offering an alternative to traditional world simulators.
- This is a key technology for creating vast and varied worlds for gaming and simulation.
- ğŸ”— [WorldGrow GitHub](https://github.com/world-grow/WorldGrow)

---

## ğŸ”Š Foley Control
- Stability AI has introduced **Foley Control**, a lightweight approach to video-guided sound effect generation.
- It aligns a frozen text-to-audio model with video, allowing it to generate synchronized sound effects without needing to be retrained from scratch.
- This preserves the controllability of text prompts while adding the context of video.
- ğŸ”— [Foley Control Project Page](https://stability-ai.github.io/foleycontrol.github.io/)

---

## ğŸš€ Wrap Up
This week was a whirlwind of innovation, with AI pushing into new frontiers of creativity, automation, and workflow integration.
- AI is no longer just a tool; it's becoming an operating system for our digital lives.
- The open-source community continues to release models that rival the performance of proprietary systems.
- Real-time video generation and editing are becoming a reality, changing creative workflows forever.

ğŸ‘‰ What do you think? Which update is the most game-changing â€” the AI OS, the Canva killer, or the YouTube automation tools?

ğŸ’¬ Drop your thoughts in the video comments:
[Watch the full video on YouTube](https://youtu.be/9I8m1pqXIRU)

---

## ğŸ”— Follow & Support
- ğŸ¦ Twitter/X: [@airesearch_ai](https://x.com/airesearch_ai)  
- â˜• Support: [Ko-fi](https://ko-fi.com/airesearchs)  
- ğŸ¥ Subscribe for more: [AI Research YouTube](https://www.youtube.com/@airesearchofficial/)

---

#AI #AINews #AIWeekly #ArtificialIntelligence #AITools #OpenSource #AIYouTube #AIGaming #AIResearch #AITrends

ğŸ‘‰ Browse all past episodes here: [AI Weekly News Archive](../../..)
