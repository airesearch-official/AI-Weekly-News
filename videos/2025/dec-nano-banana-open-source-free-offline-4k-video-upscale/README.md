# ğŸš€ AI Weekly News â€“ December 2025
**Nano Banana Open Source, FREE Offline 4K Video Upscale, Long AI Videos, AI Plays Any Game â€“ HUGE AI**

ğŸ“… Published: December 31, 2025  
ğŸ¥ Watch the full video here:  
[![Watch on YouTube](https://img.youtube.com/vi/Y_aewarS3-g/0.jpg)](https://youtu.be/Y_aewarS3-g)

---

## ğŸ”¥ Overview
This weekâ€™s AI news is absolutely insane! From Nano Banana going open source to offline 4K video upscaling and even AI playing full video games, the AI ecosystem just exploded. We're seeing powerful new workflows unlocked, long-form video generation getting more realistic, and AI agents that can take on complex tasks in real-time.

Hereâ€™s a full breakdown with source links and insights ğŸ‘‡

---

## ğŸ¨ Qwen-Image-2512 & Spatia
- **Qwen-Image-2512** is the latest iteration of Qwen's powerful image generation model, building on the capabilities of its predecessors with even better text rendering and image quality.
- **Spatia** is a new spatial memory-aware video generation framework that explicitly preserves a 3D scene point cloud to maintain long-term spatial and temporal consistency.
- ğŸ“– [Qwen-Image Announcement](https://qwen.ai/blog?id=qwen-image-2512)
- ğŸ”— [Spatia Project Page](https://zhaojingjing713.github.io/Spatia/)

---

## ğŸ¥ Inf-Cam & Stream DiffVSR
- **Inf-Cam** is a new method for camera-controlled video generation that uses infinite homography as a robust conditioning signal, allowing for high-fidelity camera pose control without relying on error-prone depth estimation.
- **Stream DiffVSR** is a low-latency, streamable video super-resolution framework that uses auto-regressive diffusion to achieve high perceptual quality for online VSR without needing future frames.
- ğŸ”— [Inf-Cam Project Page](https://emjay73.github.io/InfCam/)
- ğŸ”— [Stream DiffVSR Project Page](https://jamichss.github.io/stream-diffvsr-project-page/)

---

## ğŸ® NitroGen & CARI4D
- **NitroGen** is a foundation model for generalist gaming agents, trained on 40,000 hours of gameplay videos across more than 1,000 games. It's a major step towards creating AI agents that can play any game.
- **CARI4D** is a category-agnostic method for reconstructing 4D human-object interaction from a single monocular video, a big leap for creating realistic digital humans and interactions.
- ğŸ”— [NitroGen Project Page](https://nitrogen.minedojo.org/)
- ğŸ”— [CARI4D Project Page](https://nvlabs.github.io/CARI4D/)

---

## âš¡ FLUX.2-dev-Turbo & MAI-UI
- **FLUX.2-dev-Turbo** is a distilled LoRA adapter for the FLUX.2 image generation model that enables high-quality image generation in just 8 inference steps, making it incredibly fast.
- **MAI-UI** is a family of foundation GUI agents from Alibaba's Tongyi Lab, designed to revolutionize human-computer interaction by enabling AI to control and operate graphical user interfaces.
- ğŸ¤— [FLUX.2-dev-Turbo on Hugging Face](https://huggingface.co/fal/FLUX.2-dev-Turbo)
- ğŸ”— [MAI-UI GitHub](https://tongyi-mai.github.io/MAI-UI/)

---

## ğŸ–¼ï¸ FlashPortrait & StoryMem
- **FlashPortrait** is an end-to-end video diffusion transformer that can synthesize ID-preserving, infinite-length videos of talking portraits at up to 6x the speed of previous methods.
- **StoryMem** is a new paradigm for long-form video storytelling that uses explicit visual memory to transform single-shot video diffusion models into multi-shot storytellers.
- ğŸ”— [FlashPortrait Project Page](https://francis-rings.github.io/FlashPortrait/)
- ğŸ”— [StoryMem Project Page](https://kevin-thu.github.io/StoryMem/)

---

## ğŸ¬ DreamMontage & Generative Refocusing
- **DreamMontage** is a new framework for generating coherent and diverse montages from a collection of videos, a powerful tool for video summarization and storytelling.
- **Generative Refocusing** is a new two-stage diffusion-based method for flexible defocus control from a single image, allowing for realistic aperture adjustments and bokeh effects.
- ğŸ”— [DreamMontage Project Page](https://dreamontage.github.io/DreaMontage/)
- ğŸ”— [Generative Refocusing Project Page](https://generative-refocusing.github.io/)

---

## ğŸƒ HY-Motion1.0 & ReCo
- **HY-Motion1.0** is a series of text-to-3D human motion generation models from Tencent, capable of creating high-quality, realistic human animations from text prompts.
- **ReCo** (Region-Constraint In-Context Generation) is a new method for instructional video editing that allows for precise control over edits like replacement, addition, and removal.
- ğŸ”— [HY-Motion1.0 GitHub](https://github.com/Tencent-Hunyuan/HY-Motion-1.0)
- ğŸ”— [ReCo Project Page](https://zhw-zhang.github.io/ReCo-page/)

---

## âœï¸ ProEdit & AniX
- **ProEdit** is a new framework for professional image editing that uses a progressive editing strategy to achieve high-quality results for complex edits.
- **AniX** is a system that allows users to animate any character in any 3D Gaussian Splatting scene using natural language commands, enabling interactive control and exploration.
- ğŸ”— [ProEdit GitHub](https://isee-laboratory.github.io/ProEdit/)
- ğŸ”— [AniX Project Page](https://snowflakewang.github.io/AniX/)

---

## ğŸ§Š MVInverse & 3D Re-GEN
- **MVInverse** is a feed-forward multi-view inverse rendering method that can reconstruct scene geometry and materials from multiple images in seconds.
- **3D-RE-GEN** is a framework for 3D reconstruction of indoor scenes from a single image, producing coherent, modifiable scenes by reconstructing individual objects and the background as textured 3D assets.
- ğŸ”— [MVInverse Project Page](https://maddog241.github.io/mvinverse-page/)
- ğŸ”— [3D Re-GEN Project Page](https://3dregen.jdihlmann.com/)

---

## ğŸš€ Wrap Up
What a way to end the year! The AI ecosystem is exploding with powerful new tools that are more accessible and capable than ever. Open source is thriving, and we're seeing breakthroughs that are fundamentally changing how we interact with technology.
- **Open source is winning**: Models like Nano Banana and FLUX.2-dev-Turbo are bringing state-of-the-art performance to everyone.
- **Video is getting real**: From long-form storytelling to real-time super-resolution, AI video is maturing at an incredible pace.
- **AI is your new copilot**: Agents like NitroGen and MAI-UI are showing us a future where AI can perform complex tasks for us, from playing games to controlling our devices.

ğŸ‘‰ What do you think was the biggest breakthrough this week? Are you more excited about open-source models or the new wave of AI agents?

ğŸ’¬ Drop your thoughts in the video comments:
[Watch the full video on YouTube](https://youtu.be/Y_aewarS3-g)

---

## ğŸ”— Follow & Support
- ğŸ¦ Twitter/X: [@airesearch_ai](https://x.com/airesearch_ai)  
- â˜• Support: [Ko-fi](https://ko-fi.com/airesearchs)  
- ğŸ¥ Subscribe for more: [AI Research YouTube](https://www.youtube.com/@airesearchofficial/)

---

#AI #AINews #AIWeekly #ArtificialIntelligence #NanoBanana #OpenSource #AIVideo #AIGaming #AIResearch #AITrends

ğŸ‘‰ Browse all past episodes here: [AI Weekly News Archive](../../..)
