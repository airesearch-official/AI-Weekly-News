# 🚀 AI Weekly News – October 2025
**Wan 2.5 is 😱, Alibaba’s Crazy AIs, Gemini’s New Model & DeepSeek Update – Huge AI NEWS!**

📅 Published: October 10, 2025  
🎥 Watch the full video here:  
[![Watch on YouTube](https://img.youtube.com/vi/ENTC2MYs7ao/0.jpg)](https://youtu.be/ENTC2MYs7ao)

---

## 🔥 Overview
This week, the AI world is buzzing with major upgrades to leading video models, a flurry of innovative releases from Alibaba's Qwen team, and significant updates from Google's Gemini and DeepSeek. From hyper-realistic video to powerful new open-source models, the pace is relentless.

Here’s a full breakdown with source links and insights 👇

---

## 🎥 Wan 2.5 – The Next Level of AI Video
- **Wan 2.5** is a major upgrade to the viral AI video model, offering insane realism and motion control.
- It can generate sound-synchronized, 4K resolution videos from images, with professional camera movements and precise lip-sync.
- This version solidifies its position as a top-tier, accessible tool for studio-quality video creation.
- 🌐 [Visit Wan.video](https://wan.video/)

---

## 🖼️ Qwen-Image New Model
- The Qwen team released a new, powerful **Qwen-Image** model for text-to-image generation.
- It excels at prompt following, aesthetics, and has a unique strength in rendering text accurately within images.
- This model is a strong contender in the open-source image generation space.
- 📖 [Read the Qwen Blog](https://qwen.ai/blog?id=1675c295dc29dd31073e5b3f72876e9d684e41c6&from=research.research-list)

---

## 💻 Qwen3-Coder
- **Qwen3-Coder** is a new, highly agentic code model from the Qwen team.
- The most powerful variant is a 480B-parameter Mixture-of-Experts (MoE) model, offering exceptional performance in coding and tool-use tasks.
- It's designed to be a more capable and responsive partner for software development.
- 🔗 [Qwen3-Coder GitHub](https://github.com/QwenLM/Qwen3-Coder)

---

## 👁️ Qwen3-VL – Vision Language Model
- **Qwen3-VL** is the latest multimodal vision-language model from the Qwen series.
- It delivers significant improvements in understanding and reasoning about both text and images in a single model.
- The model also features advanced capabilities for precise, timestamp-grounded event localization in videos.
- 📖 [Read the Qwen Blog](https://qwen.ai/blog?id=3c4280109ecf762fe430ad5cd15f18c06cfc77fd&from=home.latest-research-list)

---

## 🚀 Qwen3-Max
- The **Qwen3-Max** model has been released, positioning itself as a top-tier proprietary model.
- Benchmarks show its reasoning and math skills competing with or even exceeding models like Gemini 2.5 Pro and GPT-5.
- This release highlights the rapid advancement of foundation models from Alibaba's Qwen team.
- 📖 [Read the Qwen Blog](https://qwen.ai/blog?id=87dc93fc8a590dc718c77e1f6e84c07b474f6c5a&from=home.latest-research-list)

---

## 🌌 Qwen3-Omni
- **Qwen3-Omni** is a single, end-to-end omni-modal foundation model that processes text, images, audio, and video.
- It maintains state-of-the-art performance across all modalities without degradation, a first for a single multimodal model.
- It can deliver real-time streaming responses in both text and natural speech.
- 📖 [Read the Qwen Blog](https://qwen.ai/blog?id=65f766fc2dcba7905c1cb69cc4cab90e94126bf4&from=research.latest-advancements-list)

---

## 🤖 Kimi Ok Computer Agent
- Kimi has launched **"Ok Computer,"** an agentic mode for its AI assistant.
- This mode uses Kimi's K2 Turbo LLM to perform complex tasks like researching, compiling information, and generating documents from a single prompt.
- It represents a significant step towards more autonomous and capable AI agents.
- 🌐 [Visit Kimi.com](https://www.kimi.com/)

---

## ❤️ ChatGPT Pulse
- OpenAI has released **ChatGPT Pulse**, a new proactive experience for Pro users on mobile.
- Pulse researches topics based on your chats, feedback, and connected apps (like your calendar) to deliver personalized updates.
- It acts as a morning briefing, surfacing what matters to you before you even ask.
- 📖 [Read the announcement](https://openai.com/index/introducing-chatgpt-pulse/)

---

## 🎵 Suno V5
- The highly anticipated **Suno V5** is expected to be released soon.
- As the next iteration of the leading AI music generation model, it is expected to feature more natural-sounding vocals and higher overall audio quality.
- The release is eagerly awaited by the AI music community.
- 🌐 [Visit Suno](https://suno.com)

---

## 🏃 OmniRetarget
- **OmniRetarget** is an interaction-preserving data generation engine for humanoid robotics.
- It retargets human motions to robots, producing physically plausible and kinematically feasible trajectories.
- This is a key technology for training robots to perform complex, real-world tasks.
- 🔗 [OmniRetarget Project Page](https://omniretarget.github.io/)

---

## 🧩 Hunyuan3D-Part
- Tencent has released **Hunyuan3D-Part**, a framework for generating individual parts of 3D models.
- It uses a two-component pipeline (P3-SAM and X-Part) to detect and generate semantic parts from a holistic 3D mesh.
- This allows for more granular control and editing of complex 3D assets.
- 🔗 [Hunyuan3D-Part GitHub](https://github.com/Tencent-Hunyuan/Hunyuan3D-Part)

---

## ✨ NVIDIA Lyra
- **Lyra** is a generative 3D scene reconstruction model from NVIDIA Research.
- It uses a video diffusion model to reconstruct entire 3D scenes from video or even single-image inputs.
- This technology is crucial for creating assets for simulation, VR, and gaming environments.
- 🔗 [Lyra Project Page](https://research.nvidia.com/labs/toronto-ai/lyra/)

---

## 🧠 DeepSeek 3.1 Terminus
- DeepSeek has provided an update on **DeepSeek-V3.1**, a powerful hybrid reasoning model.
- The **Terminus** API interface is temporarily retained for comparative testing, showcasing the model's advanced agentic capabilities.
- It is a 671B parameter model that supports both thinking and non-thinking modes for efficiency.
- 📖 [Read the DeepSeek News](https://api-docs.deepseek.com/news/news250922)

---

## 🖼️ OmniInsert
- **OmniInsert** is a mask-free video insertion model that can place any reference object into a video.
- It addresses key challenges in data scarcity and achieving a balance between the inserted subject and the background scene.
- This allows for seamless and realistic object insertion without complex manual masking.
- 🔗 [OmniInsert Project Page](https://phantom-video.github.io/OmniInsert/)

---

## ⚡ Gemini 2.5 Flash & Flash-Lite
- Google has released the stable version of **Gemini 2.5 Flash-Lite**, its fastest and lowest-cost model.
- The entire Gemini 2.5 family (Pro, Flash, and Flash-Lite) is designed to be a family of hybrid reasoning models, providing a balance of performance, cost, and speed.
- These updates make powerful AI capabilities more accessible for a wider range of applications.
- 📖 [Read the Google Developers Blog](https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/)

---

## 📹 VideoFrom3D
- **VideoFrom3D** is a novel framework for generating high-quality 3D scene videos from coarse geometry and a reference image.
- It combines the strengths of image diffusion models (for visuals) and video diffusion models (for consistency) to produce photorealistic results.
- This streamlines the 3D graphic design workflow for rapid production.
- 🔗 [VideoFrom3D Project Page](https://kimgeonung.github.io/VideoFrom3D/)

---

## 🦁 Lynx
- **Lynx** is a high-fidelity personalized video generation model from ByteDance.
- It can generate a video of a specific person from just a single input image, demonstrating superior face resemblance and prompt following.
- This model advances the state of the art in creating personalized video content.
- 🔗 [Lynx Project Page](https://byteaigc.github.io/Lynx/)

---

## 🚀 Wrap Up
This week was a firehose of innovation, especially from China's top AI labs, alongside major updates from Google and OpenAI.
- AI video is hitting a new level of realism with Wan 2.5.
- Alibaba's Qwen team is on a tear, releasing a full suite of powerful open-source models.
- AI agents are getting smarter and more autonomous.

👉 What do you think? Which update blows your mind the most — Wan 2.5 or Gemini’s new model?

💬 Drop your thoughts in the video comments:
[Watch the full video on YouTube](https://youtu.be/ENTC2MYs7ao)

---

## 🔗 Follow & Support
- 🐦 Twitter/X: [@airesearch_ai](https://x.com/airesearch_ai)  
- ☕ Support: [Ko-fi](https://ko-fi.com/airesearchs)  
- 🎥 Subscribe for more: [AI Research YouTube](https://www.youtube.com/@airesearchofficial/)

---

#AI #AINews #AIWeekly #ArtificialIntelligence #Wan2.5 #Qwen3 #Gemini #DeepSeek #AIResearch #AITrends

👉 Browse all past episodes here: [AI Weekly News Archive](../../..)
